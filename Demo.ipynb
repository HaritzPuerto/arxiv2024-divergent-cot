{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e9edea-24d0-46c2-9e8f-1feee3aa40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d3f80-912c-477a-8e10-3bac7a512808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one of the following cells to select the model you want to run\n",
    "base_model_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "peft_model_id = \"haritzpuerto/LLaMA2-7B-dcot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5891f6c-0eae-4be9-b085-9e62dc13d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"meta-llama/Llama-2-13b-hf\"\n",
    "peft_model_id = \"haritzpuerto/LLaMA2-13B-dcot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12853efe-b4f3-42aa-9845-cb6fb2b1f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"microsoft/phi-1_5\"\n",
    "peft_model_id = \"haritzpuerto/phi-1.5-dcot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1baffc98-d303-4b21-afdc-9a9ec54ea1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"microsoft/phi-2\"\n",
    "peft_model_id = \"haritzpuerto/phi-2-dcot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557e9f9-fb2a-41e6-ae36-351dcd395b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one of the following cells to select the model you want to run\n",
    "base_model_path = \"meta-llama/Llama-2-70b-hf\"\n",
    "peft_model_id = \"haritzpuerto/LLaMA2-70B-dcot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da348762-ec18-4656-af23-036a339acb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84ec61406354e1ea5e72709957ce4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ukp-storage-1/puerto/miniconda3/envs/ccot/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_path,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "# the model is loaded in fp16, feel free to use 8bit if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ccd84c-f17a-4fb4-b97d-814f38e7bf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f32ab1fb99045b6bda767bbb966aa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7070230cbe49cc850a290439ad7990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/210M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_adapter(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04259c7-30af-44a4-94b9-e9f09e791856",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af45a4b2-ec3e-483c-9fb5-464d982db745",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"[Question] Juan and LaKeisha roll a few objects down a ramp. They want to see which object rolls the farthest. What should they do so they can repeat their investigation?\\n[Options] A) Put the objects in groups. B) Change the height of the ramp. C) Choose different objects to roll. D) Record the details of the investigation.\\n[Number of answers] 2\\n[Answer 1] \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b105c28-e293-4428-a3d3-35d5ab17306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06eede0a-2c5f-4438-8eee-9e2f3d00d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**inputs.to(\"cuda\"), max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932a1b40-4db8-4d24-b3dd-fc068c9390f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [Question] Juan and LaKeisha roll a few objects down a ramp. They want to see which object rolls the farthest. What should they do so they can repeat their investigation?\n",
      "[Options] A) Put the objects in groups. B) Change the height of the ramp. C) Choose different objects to roll. D) Record the details of the investigation.\n",
      "[Number of answers] 2\n",
      "[Answer 1] 1. What is the purpose of repeating an investigation?\n",
      "The purpose of repeating an investigation is to verify the results and ensure that they are consistent.\n",
      "\n",
      "2. What should be done to repeat an investigation?\n",
      "To repeat an investigation, the same steps should be followed as closely as possible. This includes using the same objects, starting position, and speed.\n",
      "\n",
      "3. Which option would allow for the same steps to be followed?\n",
      "Option D) Record the details of the investigation. By recording the details, the same steps can be followed to repeat the investigation.\n",
      "\n",
      "4. Which option would change the investigation?\n",
      "Option A) Put the objects in groups. This would change the experiment as it would introduce a variable that was not present in the original investigation.\n",
      "\n",
      "5. Which option would change the results?\n",
      "Option B) Change the height of the ramp. This would change the results as it would affect the distance traveled by the objects.\n",
      "\n",
      "6. Which option would not change the investigation?\n",
      "Option C) Choose different objects to roll. This would not change the investigation as it would still involve rolling objects down a ramp.\n",
      "\n",
      "Therefore, the correct answer is D) Record the details of the investigation.\n",
      "[Answer 2] Step 1: What is the purpose of repeating an investigation?\n",
      "The purpose of repeating an investigation is to ensure that the results are consistent and reliable.\n",
      "\n",
      "Step 2: What should be done to ensure consistent and reliable results?\n",
      "To ensure consistent and reliable results, Juan and LaKeisha should record the details of their investigation. This includes the type of objects they used, the distance of the ramp, and the direction in which they rolled the objects.\n",
      "\n",
      "Step 3: What should they avoid when repeating their investigation?\n",
      "They should avoid changing the type of objects they used, the distance of the ramp, and the direction in which they rolled the objects. This would make it difficult to compare the results of their first investigation with their second investigation.\n",
      "\n",
      "Step 4: What should they do to change their investigation?\n",
      "They should change the height of the ramp. This would make it easier to observe any differences in the distance traveled by the objects.\n",
      "\n",
      "Step 5: What is the best answer to the question?\n",
      "The best answer to the question is D) Record the details of the investigation.\n",
      "\n",
      "[Final answer] D) Record the details of the investigation.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de57e6a-0557-42fc-87d4-7df3e46b49d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
